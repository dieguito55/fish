import torch
from transformers import pipeline
from sqlalchemy.orm import Session
from sqlalchemy import func
from backend import db, models
from datetime import datetime

# --- CONFIGURACI칍N DEL MODELO ---
# Usamos un modelo GPT-2 ligero en espa침ol para dar "toque humano"
print("游 Cargando modelo de generaci칩n de texto (puede tardar la primera vez)...")
generator = pipeline('text-generation', model='DeepESP/gpt2-spanish', max_length=100)

def get_daily_stats(db_session: Session):
    """Extrae las m칠tricas duras de la base de datos"""
    today = datetime.now().date()
    
    # Consultas SQL optimizadas
    total_fish = db_session.query(func.sum(models.DetectionEvent.num_fish)).scalar() or 0
    avg_fps = db_session.query(func.avg(models.DetectionEvent.fps)).scalar() or 0
    avg_conf = db_session.query(func.avg(models.DetectionEvent.avg_confidence)).scalar() or 0
    
    # Calcular Hora Pico (un poco m치s complejo en SQL, simplificado aqu칤)
    # En producci칩n har칤as un GROUP BY hour, aqu칤 simulamos con el 칰ltimo evento
    last_event = db_session.query(models.DetectionEvent).order_by(models.DetectionEvent.timestamp.desc()).first()
    # El timestamp est치 en hora local del sistema
    last_seen = last_event.timestamp.strftime("%H:%M") if last_event else "N/A"

    return {
        "date": today.strftime("%d/%m/%Y"),
        "total": total_fish,
        "fps": round(avg_fps, 1),
        "conf": round(avg_conf, 2),
        "last_seen": last_seen
    }

def generate_report():
    """Genera el reporte final usando IA + Datos"""
    session = db.SessionLocal()
    try:
        stats = get_daily_stats(session)
        
        # 1. Usar Transformer para generar una "apertura" creativa
        # Le damos un pie forzado para que empiece hablando de monitoreo
        prompt = "El sistema de monitoreo ambiental ha registrado hoy actividad importante. En resumen,"
        # Generamos texto (ajustamos randomness para que no alucine demasiado)
        intro_generated = generator(prompt, num_return_sequences=1, do_sample=True, temperature=0.7)[0]['generated_text']
        
        # Cortamos la generaci칩n en el primer punto para que sea una frase limpia
        intro_clean = intro_generated.split('.')[0] + "."

        # 2. Fusi칩n: IA Creativa + Datos Reales (T칠cnica: Slot Filling)
        # Esto asegura que los n칰meros sean 100% reales (la IA a veces inventa n칰meros)
        report_body = (
            f" {intro_clean} "
            f"Hasta el momento ({stats['last_seen']}), se han detectado un total de **{stats['total']} espec칤menes**. "
            f"El rendimiento del sistema se mantiene estable con un promedio de {stats['fps']} FPS "
            f"y una confianza de detecci칩n del {int(stats['conf']*100)}%. "
        )
        
        # Clasificaci칩n simple de estado basada en reglas
        status = "游릭 칍ptimo" if stats['fps'] > 15 else "游댮 Sobrecarga"
        
        final_report = f"""
        游늶 **REPORTE AUTOM츼TICO - FISHWATCH**
        Fecha: {stats['date']}
        -------------------------------------
        {report_body}
        
        Estado del Sistema: {status}
        """
        return final_report

    finally:
        session.close()

if __name__ == "__main__":
    print(generate_report())